{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [DecisionTreeClassifier(),RandomForestClassifier(), ExtraTreesClassifier() , XGBClassifier(),GaussianNB(),KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "trainAccuracy = list()\n",
    "testAccuracy = list()\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "for mdl in model:\n",
    "    trainResult = cross_val_score(mdl, X_train, y_train, scoring='accuracy', cv=kfold)\n",
    "    trainAccuracy.append(trainResult.mean())\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    testResult = metrics.accuracy_score(y_test, y_pred)\n",
    "    testAccuracy.append(testResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comparision\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.708498</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.806126</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ExtraTreeClassifier(random_state=2040281990),...</td>\n",
       "      <td>0.797826</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.762253</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.819368</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.637945</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Train_Accuracy  \\\n",
       "0                           DecisionTreeClassifier()        0.708498   \n",
       "1  (DecisionTreeClassifier(max_features='auto', r...        0.806126   \n",
       "2  (ExtraTreeClassifier(random_state=2040281990),...        0.797826   \n",
       "3  XGBClassifier(base_score=0.5, booster='gbtree'...        0.762253   \n",
       "4                                       GaussianNB()        0.819368   \n",
       "5                             KNeighborsClassifier()        0.637945   \n",
       "\n",
       "   Test_Accuracy  \n",
       "0       0.802632  \n",
       "1       0.828947  \n",
       "2       0.842105  \n",
       "3       0.776316  \n",
       "4       0.828947  \n",
       "5       0.644737  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The comparision\\n')\n",
    "modelScore = pd.DataFrame({'Model' : model, 'Train_Accuracy' : trainAccuracy, 'Test_Accuracy' : testAccuracy})\n",
    "modelScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83        33\n",
      "           1       0.85      0.91      0.88        43\n",
      "\n",
      "    accuracy                           0.86        76\n",
      "   macro avg       0.86      0.85      0.85        76\n",
      "weighted avg       0.86      0.86      0.85        76\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('ExtraTreeClassifier\\n')\n",
    "model = ExtraTreesClassifier(n_estimators=200,max_depth=150)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test,pred))\n",
    "sns.heatmap(confusion_matrix(y_test,pred), annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
