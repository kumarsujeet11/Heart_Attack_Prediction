{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [DecisionTreeClassifier(),RandomForestClassifier(), ExtraTreesClassifier() , XGBClassifier(),GaussianNB(),KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\sujee\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "trainAccuracy = list()\n",
    "testAccuracy = list()\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "for mdl in model:\n",
    "    trainResult = cross_val_score(mdl, X_train, y_train, scoring='accuracy', cv=kfold)\n",
    "    trainAccuracy.append(trainResult.mean())\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    testResult = metrics.accuracy_score(y_test, y_pred)\n",
    "    testAccuracy.append(testResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comparision\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.712451</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.815020</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ExtraTreeClassifier(random_state=97380368), E...</td>\n",
       "      <td>0.793281</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.762253</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.819368</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.637945</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Train_Accuracy  \\\n",
       "0                           DecisionTreeClassifier()        0.712451   \n",
       "1  (DecisionTreeClassifier(max_features='auto', r...        0.815020   \n",
       "2  (ExtraTreeClassifier(random_state=97380368), E...        0.793281   \n",
       "3  XGBClassifier(base_score=0.5, booster='gbtree'...        0.762253   \n",
       "4                                       GaussianNB()        0.819368   \n",
       "5                             KNeighborsClassifier()        0.637945   \n",
       "\n",
       "   Test_Accuracy  \n",
       "0       0.802632  \n",
       "1       0.815789  \n",
       "2       0.828947  \n",
       "3       0.776316  \n",
       "4       0.828947  \n",
       "5       0.644737  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The comparision\\n')\n",
    "modelScore = pd.DataFrame({'Model' : model, 'Train_Accuracy' : trainAccuracy, 'Test_Accuracy' : testAccuracy})\n",
    "modelScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        33\n",
      "           1       0.83      0.88      0.85        43\n",
      "\n",
      "    accuracy                           0.83        76\n",
      "   macro avg       0.83      0.82      0.82        76\n",
      "weighted avg       0.83      0.83      0.83        76\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('ExtraTreeClassifier\\n')\n",
    "model = ExtraTreesClassifier(n_estimators=200,max_depth=150)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test,pred))\n",
    "sns.heatmap(confusion_matrix(y_test,pred), annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
